# 算法时间复杂度

常见算法时间复杂度由大道小依次为：**Ο(1)＜Ο(log2n)＜Ο(n)＜Ο(nlog2n)＜Ο(n2)＜Ο(n3)＜…＜Ο(2n)＜Ο(n!)**

求解算法时间复杂度的具体步骤：

1. 找出算法中的基本语句：算法中执行次数最多的那条语句就是基本语句，通常是最内层循环的循环体。
2. 计算基本语句的执行次数的数量级。
3. 用大O记号表示算法的时间性能。

如果算法中包含嵌套循环，基本语句通常是最内层的循环体;如果算法中包含并列循环，则将并列循环的时间复杂度相加。

Ο(1)表示基本语句的执行次数是一个常数，一般来说，只要算法中不存在循环语句，其时间复杂度就是Ο(1)。其中**Ο(log2n)、Ο(n)、 Ο(nlog2n)、Ο(n2)和Ο(n3)**称为多项式时间，而**Ο(2n)和Ο(n!)**称为指数时间。

计算算法时间复杂度的几个简单程序分析法则：

1. 简单的输入输出语句或者赋值语句，近似认为需要O(1)时间。
2. 顺序结构，需要依次执行一系列语句所用的时间，可采用O下求和法则。
3. 选择结构，if语句，主要耗费时间是在执行then字句或else字句;校验条件也需要O(1)时间。
4. 循环结构，循环语句的运行时间主要体现在多次迭代中执行循环体以及检验循环条件的时间耗费，一般可用大O下乘法法则。
5. 复杂算法，可以将它分为几个容易估算的部分，然后利用求和法则和乘法法则计算整个算法的时间复杂度。

常用算法时间复杂度和空间复杂度：

![](常用算法时间复杂度.png)

常用排序时间复杂度：

![](常用排序时间复杂度.png)

# 冒泡排序及时间复杂度

冒泡排序的思想是：通过无序区中相邻记录关键字间的比较和位置交换，使关键字的记录如气泡一般逐渐往上漂浮至水面。

整个算法是**从最下面的记录**开始，对每两个相邻的关键字进行比较，且使关键字较小的记录切换至关键字较大的记录之上，使得经过一趟冒泡排序之后，关键字最小的记录到达最上端，接着在剩下的记录中找关键字最小的记录，并把它换到第二个位置上。以此类推，一直到所有记录都有序为止。

时间复杂度：

对于长度为n的数组，需要进行n-1趟操作，才能确保排序完成，时间复杂度为O(n^2)。

空间复杂度：

排序过程中需要一个临时变量进行两两交换，需要的额外空间为1，空间复杂度为O(1)。

稳定性：

冒泡排序在排序过程中，元素两两交换时，相同元素的前后顺序并没有改变，所以是稳定排序算法。

代码实现：

```java
package me.cxis;

import java.util.Arrays;

public class BubbleSort {

    public static int[] bubbleSort(int[] originArray) {
        System.out.println("排序之前的数组：" + Arrays.toString(originArray));
        for (int i = 1; i < originArray.length; i++) {
            for (int j = originArray.length - 1; j > i - 1; j-- ) {
                if (originArray[j] < originArray[j-1]) {
                    int tmp = originArray[j-1];
                    originArray[j-1] = originArray[j];
                    originArray[j] = tmp;
                }
            }
            System.out.println("第" + (i + 1) + "次排序后的数组：" + Arrays.toString(originArray));
        }
        System.out.println("排序之后的数组：" + Arrays.toString(originArray));
        return originArray;
    }

    public static void main(String[] args) {
        int[] originArray = {3, 4, 1, 9, 5, 6, 2};
        bubbleSort(originArray);

    }
}

```

## 排序算法的稳定性

排序算法的稳定是指：相同的值在排序过后相对位置不变。也就是保证排序前两个相等的数的前后顺序，和排序后它们两个的前后位置顺序相同。



# 了解AQS吗？AQS源码等

AQS即AbstractQueuedSynchronizer，队列同步器，用来构建锁和其他同步组件的框架。

## AQS的核心思想

如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效工作线程，并且将共享资源设置为锁定状态；如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制在AQS中是使用CLH队列锁来实现的，即将暂时获取不到锁的线程加入到队列中。

CLH队列是一个虚拟双向队列，即不存在队列实例，仅存在结点之间的关联关系。AQS将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。

## AQS实现

AQS维护一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被阻塞时会进入此队列）。state访问方式有下面三种：

- getState()
- setState()
- compareAndSetState()

AQS定义两种资源共享方式：

- Exclusive，独占：只有一个线程能执行，比如ReentrantLock。
- Share，共享：多个线程可同时执行，比如Semaphore和CountDownLatch。

不同的自定义同步器争用共享资源的方式也不同。自定同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队或唤醒出队等）AQS已经在顶层实现好。

自定义同步器实现时主要实现以下几种方法：

- isHeldExclusively()：该线程是否正在独占资源，只有用到Condition才需要实现它。
- tryAcquire(int)：独占方式，尝试获取资源，成功返回true；失败返回false。
- tryRelease(int)：独占方式，尝试释放资源，成功返回true；失败返回false。
- tryAcquireShared(int)：共享方式，尝试获取资源，负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
- tryReleaseShared(int)：共享方式，尝试释放资源，成功返回true；失败返回false。

## 自定义同步器

### ReentrantLock

state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state加1。此后，其他线程再尝试获取tryAcquire()时就会失败，直到A线程unlock()到state为0（即释放锁）为止，然后其他线程才有机会获取该锁。

当然，释放锁之前，A线程自己是可以重复获取此锁的，state会累加，这就是可重入的概念。获取多少次就要释放多少次，这样才能保证state是能回到0状态的。

### CountDownLatch

任务分为N个子线程去执行，state初始化为N。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后（即state=0），会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。

一般来说，自定义同步器要么是独占方式，要是是共享方式，只需要实现tryAcquire和tryRelease或者实现tryAcquireShared和tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。

# ReentrantLock原理以及源码

是可重入的互斥锁，和synchronized语义类似，都具有可重入性，ReentrantLock增加了一些高级功能，比如实现了公平锁，还可以绑定多个Condition。

- 可重入性：可以支持一个线程对锁的重复获取。
- 公平锁/非公平锁：公平锁，多个线程获取同一个锁的时候，必须按照严格的锁的申请时间来依次获得锁；非公平锁，当锁被释放时候，等待中的线程均有机会获得锁。synchronized是非公平锁，ReentrantLock默认也是非公平锁，可以通过构造方法来指定使用公平锁。一般非公平锁性能比公平锁好。

synchronized是Java原生的互斥同步锁，使用方便，无需显式释放锁。底层是通过monitorenter和monitorexit两个字节码指令来实现加锁和解锁操作的。ReentrantLock做为API层面的互斥锁，需要显式的加锁和解锁。

ReentrantLock内部定义了三个静态内部类：Sync、FairSync、NoFairSync。Sync继承了AQS，其他两个继承Sync，各自完成公平和非公平的逻辑。

公平性和非公平性的区别是：在尝试获取锁的时候多了一个判断，公平锁在尝试获取锁的时候先判断是否有比自己申请早的线程在同步队列中等待，有，则等待；没有就抢占。

# Synchronized实现原理

理解要点：

- 理解synchronized的实现方式：monitorenter和monitorexit。
- 为什么称为重量级锁。
- 对重量级锁的优化：自旋锁和自适应自旋锁。
- 演化：轻量级锁。
- 演化：偏向锁。

## 实现及重量级锁

synchronized是Java中最基本的互斥同步手段，编译之后会在同步块的前后添加monitorenter和monitorexit两个字节码指令。同步块在已经进入的线程执行完之前，会阻塞后面其他的线程，在Java中线程是映射到操作系统的原生线程之上，阻塞线程就会涉及到用户态切换到核心态等等，所以synchronized被称为**重量级锁**。

## 自旋锁

互斥同步对性能最大的影响就是阻塞的实现，一般共享的锁定状态只会持续很短时间，如果物理机器上有一个以上的处理器，可以让两个或以上的线程同时并行执行，就可以让后来请求锁的线程稍微等待一下，但是不放弃处理器的执行时间。为了让线程等待，只需要让线程执行一个忙循环（自旋），这就是**自旋锁**。

自旋锁不能代替阻塞，自旋本身虽避免了线程切换的开销，但是要占用处理器的时间，如果占用时间长就会浪费处理器资源。自旋锁实现上设置了一个限度，**默认自旋次数是10次**，超过次数就使用传统方式挂起线程。

## 自适应自旋锁

JDK1.6中引入了**自适应的自旋锁**，意味着自旋时间不再固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获取锁，并且持有锁的线程正在运行中，虚拟机就会认为这次自旋也很有可能再次成功，就会允许自旋等待持续更长时间；如果对于某个锁，自旋很少成功获得，那么在以后要获取这个锁时可能忽略掉自旋过程，避免资源浪费。

## 轻量级锁

**轻量级锁**是JDK1.6加入的，本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。虚拟机进入同步块的时候会先使用轻量级锁，如果发现有两条以上的线程竞争同一个锁，轻量级锁就会膨胀为重量级锁。

轻量级锁使用CAS操作避免了使用互斥量的开销，但是如果存在竞争，除了互斥量的开销外，还额外发生了CAS操作，因此在有竞争情况下，轻量级锁会比重量级锁更慢。

## 偏向锁

**偏向锁**也是在JDK1.6中引入的一项锁优化，目的是消除数据在无竞争情况下的同步原语。轻量级锁是在无竞争情况下使用CAS去消除同步使用的互斥量，偏向锁就是在无竞争情况下把整个同步都消除掉。

偏向锁会偏向于第一个获得他的线程，如果在接下来的执行过程中，该锁没有被其他线程获取，则持有偏向锁的线程永远不需要再进行同步。当另外一个线程去尝试获取这个锁的时候，偏向锁就宣告结束。

## 轻量级锁和偏向锁的实现

都是存储在对象头（Mark Word）中。

# CAS实现原理以及缺点

理解要点：

- CAS通过unsafe的方法实现：有三个操作数，内存值V，旧的预期值A，要修改的新值B，当且仅当预期值A和内存值V相同时，将内存值V改为B，否则什么都不做。
- 方法的参数：第一个参数是要修改的对象；第二个参数是对象中要修改变量的偏移量；第三个是修改前的值；第四个是修改后的值。
- 系统级别实现：CAS是借助CPU底层指令来完成的。
- CAS缺点：ABA问题，以及怎么解决

**ABA问题**，CAS在操作值的时候，需要检查下值有没有变化，没有发生变化则更新。但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS检查的时候会发现它的值没有发生变化，但是实际上却发生了变化！

ABA解决思路是使用版本号，在变量前追加版本号，每次变量更新的时候把版本号加1。从JDK1.5开始提供了一个类AtomicStampedReference来解决ABA问题，它通过控制变量值的版本来保证CAS的正確性。

# HashMap和ConcurrentHashMap

HashMap底层实现是数组加链表的形式，添加数据的时候，首先根据key的hash值来计算在数组中的索引，当找到的位置有数据存在时，会在当前索引处使用链表来存储hash值相等的数据，查找链表中的数据会通过key的equals方法来判断。

在JDK1.8中HashMap采用数组加链表和红黑树的方式实现，当链表长度超过8的时候，链表就转换为红黑树进行存储。

HashMap不是线程安全的。

ConcurrentHashMap采用分段锁实现线程安全，底层实现还是数组和链表的形式。ConcurrentHashMap中有个Segment数组，这个Segment其实就是一把锁。每个Segment中还是数组和链表的形式，跟HashMap一样。

每个Segment是一把锁，ConcurrentHashMap写操作只会锁住一段Segment，其他的Segment不会被锁住，就是利用这种方式来实现并发和线程安全的。

JDK1.8中发生了变化，取消了Segments字段，采用了类似HashMap的数组加链表和红黑树的形式实现，可以实现对每一行数据进行加锁，利用CAS和synchronized进行高效的同步更新数据。

# Java内存模型/JMM

Java内存模型用来屏蔽各种硬件和操作系统间的内存访问差异。在JSR-133实现中逐步完善和成熟。Java内存模型分为主存和工作内存，所有的变量都存储在主存中，每条线程还有自己的工作内存，线程的工作内存中保存了所使用的变量的主存的副本拷贝，线程对变量的操作都必须在工作内存中进行。

# volatile的理解

被volatile修饰的变量一般会有两个特性：

- 保证了不同线程对该变量操作的内存可见性。
- 禁止指令重排序。

内存可见性，首先需要说一下JMM也就是Java内存模型，分为主存和工作内存，所有变量都存储在主存中，每个线程都有自己的工作内存，存储着需要的变量的主存的副本，对变量的操作都在工作内存中进行，操作完成之后，需要将变量写回主存中，如果有多个线程都操作，可能会造成缓存不一致的问题。而使用volatile关键字修饰变量，就可以解决这个问题，来保证内存可见性，对一个变量的修改会立刻回写到主存，其他线程需要该变量时，会去主存中读取新值。

volatile只能保证可见性和有序性，但是不能保证原子性。

# Java深克隆和浅克隆/深拷贝和浅拷贝

浅克隆：复制一个对象的实例，但是该对象中包含的其他的对象还是公用的，不会克隆一份。一般使用super.clone()，clone的对象就是浅克隆。

深克隆：复制一个对象的实例，而且这个对象中包含的其他的对象也要复制一份。

# Java内存区域/Java运行时数据区域

- 程序计数器：当前线程所执行的字节码的行号指示器，是线程私有的。
- Java虚拟机栈：是线程私有的，与线程的生命周期相同。虚拟机栈描述的是Java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。
- 本地方法栈：执行本地方法服务的。
- Java堆：虚拟机管理的内存中最大的一块，是被所有线程共享的，在虚拟机启动的时候创建，用来存放对象实例。所有的对象和数组都要在堆上分配。Java堆可以分为新生代和老年代；新生代可分为Eden空间，From Suvivor空间和To Suvivor空间等。
- 方法区：是各个线程共享的内存区域，用于存储虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

# 垃圾回收机制/垃圾收集算法

- 标记-清除
- 复制
- 标记-整理
- 分代收集

## 标记-清除算法

首先标记出所有需要回收的对象，在标记完成之后要统一回收所有被标记的对象。标记和清除的效率都不高，在标记清除之后会产生大量不连续的空间碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。

## 复制算法

复制算法将内存划分为大小相等的两块，每次只使用其中的一块。当一块内存使用完了，就将还存在着的对象复制到另外一块上，然后把已使用的内存空间一次清理掉。但是这样就会把内存缩小为原来的一半，代价有点高。

现在的虚拟机，将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden空间和其中一块Survivor空间。当回收时，将Eden和Survivor中还活着的对象一次性复制到另外一个Survivor空间上，然后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor比例是8：1。

## 标记-整理算法

老年代一般使用标记整理算法，标记过程首先标记出需要清理的对象，然后将所有存活的对象都向一端移动，最后直接清理掉端边界以外的内存。

## 分代收集算法

分代收集是将上面的算法组合使用，Java堆一般分为新生代和老年代，新生代使用复制算法，老年代使用标记整理或者标记清理算法。

# 内存分配策略

**对象优先分配在新生代的Eden区**，当Eden区没有足够的空间进行分配时，虚拟机会执行一次Minor GC。如果还找不到足够空间，就通过担保机制提前分配到老年代中去。

**大对象直接进入老年代**，虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区以及两个Survivor区域之间发生大量的内存复制。

**长期存活对象进入老年代**，虚拟机为每个对象定义了一个年龄计数器，每经过一次Minor GC存活的对象年龄就加1，当年龄增加到一定程度，默认为15，就会晋升到老年代中。

**动态对象年龄判定**，如果Survivor区中相同年龄的对象大小总和大于Survivor空间的一半，则年龄大于或者等于该年龄的对象直接进入老年代。

**空间分配担保**，每次进行Minor  GC时，JVM会计算Survivor区移到老年代的对象的平均大小。如果这个值大于老年代的剩余值大小则进行一次Full GC，如果小于就检查HandlePromotionFailure设置，如果为true，就进行Minor GC，如果为false就进行Full GC。



# Minor GC/Major GC/Full GC

Minor GC，发生在新生代的垃圾收集动作，Minor GC发生频繁，回收速度也比较快。

Major GC/Full GC，发生在老年代的GC，出现了Major GC一般会伴随至少一次Minor GC。Major GC一般会比Minor GC慢10倍。

# 类的生命周期

- 加载
- 链接：验证、准备、解析
- 初始化
- 使用
- 卸载

# 类加载过程

## 加载

在加载阶段，虚拟机需要完成：

- 通过一个类的全限定名获取定义此类的二进制字节流。
- 将字节流所代表的静态存储结构转化为方法区的运行时数据结构。
- 在内存中生成一个代表这个类的Class对象，作为方法区这个类的访问的入口。

加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，然后在内存中实例化一个Class类的对象，这个对象存储在方法区中，这个对象作为程序访问方法区中的这个类的外部接口。

## 验证

验证是为了确保Class文件中字节流中包含的信息符合当前虚拟机的要求，并且不会损害虚拟机自身的安全。

- 文件格式验证
- 元数据验证
- 字节码验证
- 符号引用验证

## 准备

准备阶段是正式为类变量分配内存并设置类变量初始值的阶段。类变量所使用的内存都在方法区中进行分配。

## 解析

解析阶段是虚拟机将常量池中的符号引用替换为直接引用的过程。

## 初始化

类初始化阶段是类加载过程的最后一步，这个阶段才是真正开始执行类中定义的Java代码。初始化阶段是执行类构造器`<clinit>()`方法的过程。

- `<clinit>()`方法是由编译器自动收集类中所有类变量的赋值动作和静态语句块中的语句合并产生的。编译器收集的顺序是由语句在源文件中出现的顺序决定的。
- `<clinit()>`方法和实例构造器`<init>()`方法不同，类构造器方法不需要显式调用父类构造器，虚拟机会保证在子类的`<clinit>()方法执行之前，父类的类构造器方法已经执行完成。`
- 由于父类的类构造器方法先执行，所以父类中定义的静态语句块要优先于子类的变量赋值操作。
- 如果一个类中没有静态语句块，编译器可以不为这个类生产`<clinit>()`方法。
- 接口没有静态语句块，但是有变量初始化赋值操作，所以接口也会有类构造器方法，但是执行接口的类构造器方法不需要先执行父接口的`<clinit>()`方法。接口的实现类初始化时也不会执行接口的类构造器方法。
- 虚拟机会保证类的`<clinit>()`方法的线程安全。

# 对象在内存中的初始化过程/对象的创建

对象的初始化和创建的大致过程如下，虚拟机遇到一个new指令，会首先在常量池中去定位到一个类的符号引用，并检查这个符号引用代表的类是否被加载、解析和初始化过。如果没有的话，先执行类的加载过程。在类加载检查通过后，虚拟机会为新生对象分配内存。内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值，这能保证对象的实例字段在Java代码中不赋予初始值就可以直接使用。接下来虚拟机要对对象进行必要的设置，例如是哪个类的实例，如何才能找到类的元数据信息等。之后会执行`<init>`方法，把对象按照程序员的意愿进行初始化。



当一个对象被创建时，虚拟机就会为其分配内存来存放对象自己的实例变量以及从父类继承过来的实例变量，在为这些实例变量分配内存的同时，这些实例变量也会被赋予默认值。内存分配完成之后，Java虚拟机就会开始对新创建的对象按照程序员的意志进行初始化。Java对象初始化过程中，主要涉及三种执行对象初始化的结构：

- 实例变量初始化
- 实例代码块初始化
- 构造函数初始化

## 实例变量初始化以及实例代码块初始化

在定义实例变量的同时，还可以直接对实例变量进行赋值或者使用实例代码块进行赋值，它们将在构造函数执行之前完成这些初始化操作。

如果我们对实例变量直接赋值或者使用实例代码块赋值，编译器会将其中的代码放到类的构造函数中去，并且这些代码会被放在对超类构造函数的调用语句之后，构造函数本身的代码之前。**Java要求构造函数的第一条语句必须是超类构造函数的调用语句**

## 构造函数初始化

实例变量和实例代码块初始化总是发生在构造方法初始化之前。编译生成的字节码中这些构造函数会被命名成`<init>()`

Java要求在实例化之前必须实例化其超类，以保证所创建实例的完整性，Java强制要求除了Object对象之外所有的对象的构造方法的第一条语句必须是超类构造方法的调用语句。默认编译器会为我们自动生成一个对超类构造方法的调用。

**类实例化的过程**：父类的类构造器`<clinit>()` --> 子类的类构造器`<clinit>()` --> 父类的成员变量和实例代码块 --> 父类构造方法 --> 子类的成员变量和实例代码块 --> 子类的构造方法。

# Spring AOP应用场景以及原理

AOP适合于那些具有横切逻辑的应用，比如：性能监测，访问控制，事务管理，缓存，对象池管理以及日志记录。AOP将这些分散在各个业务逻辑中的代码通过横向切割的方式抽取到一个独立的模块中。

AOP实现的关键就在于AOP框架自动创建的AOP代理，AOP代理可以分为静态代理和动态代理：

- 静态代理，在编译阶段就可以生成AOP代理类，也称为编译时增强。
- 动态代理，借助JDK动态代理或者CGLIB等动态生成代理类，也称为运行时增强。

Spring AOP使用的是动态代理的方式，在运行是动态生成代理类。