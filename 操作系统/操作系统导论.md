# 第1章 关于本书的对话

三个关键概念：

- virtualization（虚拟化）
- concurrency（并发）
- persistence（持久性）

# 第2章 操作系统介绍

推荐书籍：

- 《Introduction to Computing Systems: From Bits and Gates to C and Beyond》Yale N. Patt and Sanjay J. Patel McGraw-Hill, 2003

- 《Computer Systems: A Programmer’s Perspective》 Randal E. Bryant and David R. O’Hallaron
  Addison-Wesley, 2010

程序运行时会发生什么？执行指令

处理器从内存中获取（fetch）一条指令，对其进行解码（decode）（弄清楚这是哪条指令），然后执行（execute）它（做它应该做的事情，如两个数相加、访问内存、检查条件、跳转到函数等）。完成这条指令后，处理器继续执行下一条指令，依此类推，直到程序最终完成。

如何将资源虚拟化

操作系统主要利用虚拟化（virtualization）技术，将物理（physical）资源（如处理器、内存或磁盘）转换为更通用、更强大且更易于使用的虚拟形式。有时将操作系统称为虚拟机（virtual machine）。

操作系统还提供了一些接口（API）、系统调用（system call）。由于操作系统提供这些调用来运行程序、访问内存和设备，并进行其他相关操作，有时也会说操作系统为应用程序提供了一个标准库（standard library）。

虚拟化让许多程序运行（从而共享CPU），让许多程序可以同时访问自己的指令和数据（从而共享内存），让许多程序访问设备（从而共享磁盘等），所以操作系统有时被称为资源管理器（resource manager）。

# 第4章 抽象：进程

## 4.1 抽象：进程

操作系统为正在运行的程序提供的抽象，就是进程（process）。

## 4.4 进程状态

- 运行（running）：在运行状态下，进程正在处理器上运行。这意味着它正在执行指令。

- 就绪（ready）：在就绪状态下，进程已准备好运行，但由于某种原因，操作系统选择不在此时运行。

- 阻塞（blocked）：在阻塞状态下，一个进程执行了某种操作，直到发生其他事件时才会准备运行。

# 第5章 插叙：进程API

- fork()

- exec()

- wait()

# 第6章 机制：受限直接执行

## 6.3 问题2：在进程之间切换

- 时钟中断（timer interrupt）

- 上下文切换（context switch）

# 第7章 进程调度：介绍

## 7.3 先进先出（FIFO）

先进先出（First In First Out或FIFO），也称先到先服务（First Come First Served或FCFS）

## 7.4 最短任务优先（SJF）

最短任务优先（Shortest Job First，SJF）

## 7.5 最短完成时间优先（STCF）

最短完成时间优先（Shortest Time-to-Completion First，STCF）或抢占式最短作业优先（Preemptive Shortest Job First，PSJF）

## 7.7 轮转

轮转（Round-Robin，RR）。基本思想：RR在一个时间片（time slice）内运行一个工作，然后切换到运行队列中的下一个任务，而不是运行一个任务直到结束。它反复执行，直到所有任务完成。时间片长度必须是时钟中断周期的倍数。

# 第8章 调度：多级反馈队列

多级反馈队列（Multi-level Feedback Queue，MLFQ）

## 8.1 MLFQ：基本规则

MLFQ中有许多独立的队列，每个队列有不同的优先级（priority level）。任何时刻，一个工作只能存在于一个队列中。MLFQ总是优先执行较高优先级的工作。

每个队列中可能会有多个工作，因此具有同样的优先级。在这种情况下，我们就对这些工作采用轮转调度。

MLFQ两条基本规则：

- 规则1：如果A的优先级大于B的优先级，运行A。

- 规则2：如果A的优先级等于B的优先级，轮转运行A和B。

## 8.2 尝试1：如何改变优先级

- 规则3：工作进入系统时，放在最高优先级。

- 规则4a：工作用完整个时间片后，降低其优先级。

- 规则4b：如果工作在其时间片以内主动释放CPU，则优先级不变。

## 8.3 尝试2：提升优先级

-  规则5：经过一段时间S，就将系统中所有工作重新加入最高优先级队列。

## 8.4 尝试3：更好的计时方式

- 规则4：一旦工作用完了其在某一层中的时间配额（无论中间主动放弃了多少次CPU），就降低其优先级。

# 第9章 调度：比例份额

比例份额（proportional-share），有时也称为公平份额（fair-share）。比例份额算法基于一个简单的想法：调度程序的最终目标，是确保每个工作获得一定比例的CPU时间，而不是优化周转时间和响应时间。

彩票调度（lottery scheduling），基本思想：每个一段时间，都会举行一次彩票抽奖，以确定接下来应该运行哪个进程。

## 9.1 基本概念：彩票数表示份额

彩票数（ticket）代表了进程占有某个资源的份额。一个进程拥有彩票数占总彩票数的百分比，就是它占有资源的份额。

# 第10章 多处理器调度（高级）

## 10.1 背景：多处理器架构

缓存是基于局部性（locality）的概念，局部性有两种，即时间局部性和空间局部性。时间局部性是指当一个数据被访问后，它很有可能会在不久的将来被再次访问。而空间局部性指的是，当程序访问地址为x的数据时，很有可能会紧接着访问x周围的数据。

## 10.4 单队列调度

单队列多处理器调度（Single Queue Multiprocessor Scheduling，SQMS）。

缺点：

- 缺乏可扩展性（scalability）为了保证在多CPU上正常运行，调度程序的开发者需要在代码中通过加锁来保证原子性。锁可能带来巨大的性能损失。

- 第二个问题是不能很好的保证缓存亲和性

## 10.5 多队列调度

多队列多处理器调度（Multi-Queue Multiprocessor Scheduling，MQMS）。基本调度框架包含多个调度队列，每个队列可以使用不同的调度规则。

MQMS比SQMS有明显优势，它天生更具有扩展性。队列的数量会随着CPU的增加而增加，因此锁和缓存争用的开销不是大问题。MQMS天生具有良好的缓存亲和度。所有工作都保持在固定的CPU上，因而可以很好地利用缓存数据。

缺点：负载不均衡。

让工作移动，这种技术称为迁移（migration）。通过工作的跨CPU迁移，可以真正实现负载均衡。



工作窃取（work stealing）



# 第13章 抽象：地址空间

虚拟内存：虚拟内存系统负责为程序提供一个巨大的、稀疏的、私有的地址空间的假象，其中保存了程序的所有指令和数据。操作系统在专门硬件的帮助下，通过每一个虚拟内存的索引，将其转换为物理地址，物理内存根据获得的物理地址去获取所需的信息。操作系统会同时对许多进程执行此操作，并且确保程序之间互相不会受到影响，也不会影响操作系统。

# 第14章 插叙：内存操作API

## 14.1 内存类型

运行C程序的时候，会分配两种类型的内存：

- 栈内存，它的申请和释放操作是编译器来隐式管理的，也称为自动（automatic）内存

- 堆内存，所有的申请和释放操作都由程序员显式的完成。

API：

- malloc()

- free()

- mmap()

- calloc()

- realloc()

# 第15章 机制：地址转换

基于硬件的地址转换（hardware-based address translation）简称地址转换（address translation）。利用地址转换，硬件对每次内存访问进行处理，将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。

## 15.3 动态（基于硬件）重定位

基址加界限机制（base and bound），又称动态重定位（dynamic relocation）。

每个CPU需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存器，有时称为限制（limit）寄存器。



将虚拟地址转换为物理地址，就是地址转换（address translation）技术。这种重定位是在运行时发生的，这种技术一般被称为动态重定位（dynamic relocation）



基址寄存器配合界限寄存器的硬件结构是芯片中的（每个CPU一对）。将CPU的这个负责地址转换的部分通称为内存管理单元（Memory Management Unit，MMU）。



内部碎片（internal fragmentation），指的是已经分配的内存单元内部有未使用的空间（即碎片），造成了浪费。



# 第16章 分段

## 16.1 分段：泛化的基址/界限

分段（segmentation）概念。在MMU中引入不止一个基址和界限寄存器对，给地址空间内的每个逻辑段（segment）一对。一个段只是地址空间里的一个连续定长的区域，在典型的地址空间里有3个逻辑不同的段：代码、栈、堆。分段的机制使得操作系统能够将不同的段放到不同的物理内存区域，从而避免了虚拟地址空间中的未使用部分占用物理内存。

## 16.2 我们引用哪个段

硬件在地址转换时使用段寄存器。它如何知道段内的偏移量，以及地址引用了哪个段？

显式的方式：用虚拟地址的开头几位来标识不同的段，剩余的位来表示段内偏移。

隐式的方式：硬件通过地址产生的方式来确定段。例如，如果地址由程序计数器产生，那么地址在代码段。如果基于栈或基址指针，它一定在栈段。其他地址则在堆段。

## 16.4 支持共享

为了支持共享，需要一些额外的硬件支持，这就是保护位（protection bit）。基本为每个段增加了几个位，标识程序是否能够读写该段，或执行其中的代码。

## 16.6 操作系统支持

外部碎片（external fragmentation），物理内存很快充满了许多空闲空间的小洞，因而很难分配给新的段，或扩大已有的段。



该问题的解决方案：

- 一种是紧凑（compact）物理内存，重新安排原有的段。操作系统先终止运行的进程，将它们的数据复制到连续的内存区域中去，改变它们的段寄存器中的值，指向新的物理地址，从而得到了足够大的连续空闲空间。这样做，操作系统能让新的内存分配请求成功。但是，内存紧凑成本很高，因为拷贝段是内存密集型的，一般占用大量的处理器时间。

- 另外一种做法是利用空闲列表管理算法，试图保留大的内存块用于分配。相关算法有很多：
  
  - 最优匹配（best-fit）
  
  - 最坏匹配（worst-fit）
  
  - 首次匹配（first-fit）
  
  - 伙伴算法（buddy algorithm）

# 第17章 空闲空间管理

## 17.3 基本策略

### 最优匹配

最优匹配（best fit）策略非常简单：首先遍历整个空闲列表，找到和请求大小一样或更大的空闲块，然后返回这组候选者中最小的一块。也可以称为最小匹配。只需要遍历一次空闲列表，就足以找到正确的块并返回。

简单的实现在遍历查找正确的空闲块时，要付出较高的性能代价。

### 最差匹配

最差匹配（worst fit）方法与最优匹配相反，它尝试找最大的空闲块，分割并满足用户需求后，将剩余的块加入空闲列表。最差匹配尝试在空闲列表中保留较大的块，而不是像最优匹配那样可能剩下很多难以利用的小块。

但是最差匹配同样需要遍历整个空闲列表。还会导致过量的碎片。

### 首次匹配

首次匹配（first fit）策略就是找到第一个足够大的块，将请求的空间返回给用户。剩余的空闲空间留给后续请求。

首次匹配有速度优势，不需要遍历所有空闲块，但是有时会让空闲列表开头的部分有很多小块。

### 下次匹配

下次匹配（next fit）算法多维护一个指针，指向上一次查找结束的位置。不像首次匹配那样每次都从列表的开始查找。将对空闲空间的查找扩散到整个列表中去，避免对列表开头频繁的分割。

这种策略的性能与首次匹配很接近，同样避免了遍历查找。

## 17.4 其他方式

### 分离空闲列表

分离空闲列表（segregated list），基本想法：如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只管理这样大小的对象。其他大小的请求都交给更通用的内存分配程序。



Solaris系统内核设计的厚块分配程序（slab allocator）：内核启动时，它为可能频繁请求的内核对象创建一些对象缓存（object cache），如锁和文件系统inode等。这些对象缓存分别属于不同大小的空闲列表，因此能够很快的响应内存请求和释放。如果某个缓存中的空闲空间快耗尽时，它就向通用内存分配程序申请一些内存厚块（slab）。相反，如果给定厚块中对象的引用计数为0,通用内存分配程序可以从专门分配程序中回收这些空间。

### 伙伴系统

二分伙伴分配程序（binary buddy allocator），在这种系统中，空闲空间首先从概念上被砍成大小为 $2^N$的大空间。当有一个内存分配请求时，空闲空间被递归的一分为二，直到刚好可以满足请求的大小。这时，请求的块被返回给用户。

这种策略只需允许分配2的整数次幂大小的空闲块，因此会有内部碎片的麻烦。

在块被释放时，分配程序会检查伙伴是否空闲，如果是就合二为一，会递归进行合并，知道合并整个内存区域或某一块的伙伴还没有被释放。

# 第18章 分页：介绍

有两种方法来解决大多数空间管理问题：

- 第一种是将空间分割成不同长度的分片，就像虚拟内存管理中的分段。将空间切成不同长度分片以后，空间本身会碎片化（fragmented），随着时间推移，分配内存会变得比较困难。

- 第二种是将空间分割成固定长度的分片。称为分页。分页不是将一个进程的地址空间分割成几个不同长度的逻辑段（即代码、堆、栈），而是分割成固定大小的单元，每个单元称为一页。把物理内存看成是定长槽块的阵列，叫做页帧（page frame）。每个这样的页帧包含一个虚拟内存页。

## 18.1 一个简单例子

为了记录地址空间的每个虚拟页放在物理内存中的位置，操作系统通常为每个进程保存一个数据结构，称为页表（page table）。



页表的主要作用是为地址空间的每个虚拟页面保存地址转换（address translation），从而让我们知道每个页在物理内存中的位置。



虚拟地址，分成两个组件：虚拟页面号（virtual page number，VPN）和页内的偏移量（offset）。



物理帧号（PFN）也称物理页号（physical page number，PPN）

## 18.3 页表中究竟有什么

页表就是一种数据结构，用于将虚拟地址（虚拟页号）映射到物理地址（物理帧号）。



最简单的形式称为线性页表（linear page table），就是一个数组。操作系统通过虚拟页号（VPN）检索该数组，并在该索引处查找页表项（PTE），以便找到期望的物理帧号（PFN）。



页表项（PTE）有许多不同的位：

- 有效位（valid bit），通常用于指示特定地址转换是否有效。例如，当一个程序开始运行时，它的代码和堆在其地址空间的一端，栈在另一端。所有未使用的中间空间都将被标记为无效（invalid）。通过将地址空间中所有未使用的页面标记为无效，不再需要为这些页面分配物理帧，从而节省大量内存。

- 保护位（protection bit），表明页是否可以读取、写入或执行。

- 存在位（present bit），表示该页是在物理存储器还是磁盘上（即它已被换出，swapped out）。

- 脏位（dirty bit），表明页面被带入内存后是否被修改过。

- 参考位（reference bit，也称访问位，accessed bit），有时用于追踪页是否被访问，也用于确定哪些页很受欢迎，应该保留在内存中。

# 第19章 分页：快速地址转换（TLB）

使用分页作为核心机制来实现虚拟内存，可能会带来较高的性能开销。因为要使用分页，就要将内存地址空间切分成大量固定大小的单元（页），并且需要记录这些单元的地址映射信息。因为这些映射信息一般存储在物理内存中，所以在转换虚拟地址时，分页逻辑上需要一次额外的内存访问。每次指令获取、显式加载或保存，都要额外读一次内存以得到转换信息，这慢的无法接受。



地址转换旁路缓冲存储器（translation-lookaside buffer，TLB），它是虚拟到物理地址转换的硬件缓存（cache）。对每次内存访问，硬件先检查TLB,看其中是否有期望的转换映射，如果有，就完成转换，不用访问页表。

## 19.4 TLB的内容

TLB项内容可能像下面这样：`VPN | PFN | 其他位`，VPN和PFN同时存在与TLB中，因为一条地址映射可能出现在任意位置（用硬件的术语，TLB被称为全相联的（fully-associative）缓存）。硬件并行的查找这些项，看看是否有匹配。

其他位包含：

- 有效（valid）位，用来标识该项是不是有效地址转换映射

- 保护（protection）位，用来标识该页是否具有访问权限。例如，代码页被标识为可读和可执行，而堆的页被标识为可读和可写。

- 地址空间标识符（address-space identifier）

- 脏位（dirty bit）

## 19.5 上下文切换时对TLB的处理

进程切换时如何管理TLB的内容，可能的方案有：

一种方法是在上下文切换时，简单的清空TLB，把全部有效位置为0。如果是软件管理TLB的系统，可以在发生上下文切换时，通过一条显式（特权）指令来完成；如果是硬件管理TLB，可以在页表基址寄存器内容发生变化时清空TLB。

上下文切换的时候清空TLB，会有一定开销，每次进程运行都会触发TLB未命中，如果频繁的切换进程，开销很高。

为了减少这种开销，一些系统增加了硬件支持，实现跨上下文切换的TLB共享。比如在TLB中添加了一个地址空间标识符（Address Space Identifier，ASID）。可以把ASID看成是进程标识符PID。有了地址空间标识符，TLB可以同时缓存不同进程的地址空间映射。

## 19.6 TLB替换策略

- 最近最少使用（least-recently-used，LRU）

- 随机（random）

# 第20章 分页：较小的表

## 20.1 简单的解决方案：更大的页

可以使用更大的页来减少页表的大小。

这种方法主要问题在于，大内存页会导致每页内的浪费，也就是内部碎片（internal fragmentation）。因此大多数系统在常见情况下使用相对较小的页大小：4KB或8KB

## 20.2 混合方法：分页和分段

将分页和分段结合。这种方法不是为进程的整个地址空间提供单个页表，而是为每个逻辑分段提供一个。这种方式和线性页表相比，显著的节省了内存。但是可能会导致大量的页表浪费，可能会导致外部碎片出现。

## 20.3 多级页表

多级页表（multi-level page table）。思想很简单，首先将页表分成页大小的单元，然后如果整页的页表项（PTE）无效，就完全不分配该页的页表。为了追踪页表的页是否有效，使用了名为页目录（page directory）的新结构。页目录可以告诉你页表的页在哪里，或者页表的整个页不包含有效页。

多级页表在TLB未命中时，需要从内存加载两次，才能从页表中获取正确的地址转换信息。

## 20.4 反向页表

反向页表（inverted page table），这里只保留了一个页表，其中的项代表系统的每个物理页。页表项告诉我们哪个进程正在使用此项，以及该进程的哪个虚拟页映射到此物理页。

要找到正确的项，就要搜索这个数据结构，线性扫描是昂贵的，因此通常在此基础结构上建立散列表，以加速查找。