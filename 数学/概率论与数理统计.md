# 第一章 概率论的基本概念

- 在一定条件下必然发生的现象，称为确定性现象。
- 在大量重复试验或观察中所呈现出的固有规律性，就是统计规律性。
- 在个别试验中其结果呈现出不确定性，在大量重复试验中其结果又具有统计规律性的现象，称为随机现象。

## 1 随机试验

随机试验具有的特点：

1. 可以在相同的条件下重复地进行；
2. 每次试验的可能结果不止一个，并且能事先明确试验的所有可能结果；
3. 进行一次试验之前不能确定哪一个结果会出现。

## 2 样本空间、随机事件

### （一）样本空间

随机试验E的所有可能结果组成的集合称为E的样本空间，记为S。样本空间的元素，即E的每个结果，称为样本点。

### （二）随机事件

- 称试验E的样本空间S的子集为E的随机事件，简称事件。在每次试验中，当且仅当这一子集中的一个样本点出现时，称这一事件发生。
- 由一个样本点组成的单点集，称为基本事件。
- 样本空间S包含所有的样本点，它是S自身的子集，在每次试验中它总是发生的，S称为必然事件。
- 空集 $\varnothing$不包含任何样本点，它也作为样本空间的子集，它在每次试验中都不发生， $\varnothing$称为不可能事件。

### （三）事件间的关系与事件的运算

设试验E的样本空间为S，而 $A, B, A_k (k = 1, 2, \cdots)$是S的子集。

1. 若 $A \subset B$，则称事件B包含事件A，这指的是事件A发生必导致事件B发生。
	- 若 $A \subset B$且 $B \subset A$，即 $A = B$，则称事件A与事件B相等。
2. 事件 $A \cup B = \{x | x \in A 或 x \in B \}$称为事件A与事件B的和事件。当且仅当A，B中至少有一个发生时，事件 $A \cup B$发生。
	- 称 $\bigcup \limits_{k = 1}^n A_k$为n个事件 $A_1, A_2, \cdots, A_n$的和事件；
	- 称 $\bigcup \limits_{k = 1}^{\infty} A_k$为可列个事件 $A_1, A_2, \cdots$的和事件。
3. 事件 $A \cap B = \{ x | x \in A 且 x \in B \}$称为事件A与事件B的积事件。当且仅当A，B同时发生时，事件 $A \cap B$发生。 $A \cap B$也记作 AB。
	- 称 $\bigcap \limits_{k = 1}^n A_k$为n个事件 $A_1, A_2, \cdots, A_n$的积事件；
	- 称 $\bigcap \limits_{k = 1}^{\infty}$为可列个事件 $A_1, A_2, \cdots$的积事件。
4. 事件 $A - B = \{ x | x \in A 且 x \notin B \}$称为事件A与事件B的差事件。当且仅当A发生、B不发生时事件 $A - B$发生。
5. 若 $A \cap B = \varnothing$，则称事件A与B是互不相容的，或互斥 的。这指的是事件A与事件B不能同时发生。基本事件是两两互不相容的。
6. 若 $A \cup B = S$且 $A \cap B = \varnothing$，则称事件A与事件B互为逆事件。又称事件A与事件B互为对立事件。这指的是对每次试验而言，事件A、B中必有一个发生，且仅有一个发生。A的对立事件记为 $\overline{A}$。 $\overline{A} = S - A$。

设A、B、C为事件，则有：

- 交换律： $A \cup B = B \cup A$； $A \cap B = B \cap A$。
- 结合律： $A \cup (B \cup C) = (A \cup B) \cup C$； $A \cap (B \cap C) = (A \cap B) \cap C$。
- 分配律： $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$； $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$。
- 德摩根律： $\overline{A \cup B} = \overline{A} \cap \overline{B}$； $\overline{A \cap B} = \overline{A} \cup \overline{B}$。

## 3 频率与概率

### （一）频率

**定义** 在相同的条件下，进行了n次试验，在这n次试验中，事件A发生的次数 $n_A$称为事件A发生的频数。比值 $n_A / n$称为事件A发生的频率，记作： $f_n(A)$。

频率有如下基本性质：

- $0 \leq f_n(A) \leq 1$；
- $f_n(S) = 1$；
- 若 $A_1, A_2, \cdots, A_k$是两两互不相容的事件，则 $f_n(A_1 \cup A_2 \cup \cdots \cup A_k) = f_n(A_1) + f_n(A_2) + \cdots + f_n(A_k)$。

### （二）概率

**定义** 设E是随机试验，S是它的样本空间。对于E的每一事件A赋予一个实数，记为 $P(A)$，称为事件A的概率，如果集合函数 $P(\cdot)$满足下列条件：

- 非负性：对于每一个事件A，有 $P(A) \geq 0$；
- 规范性：对于必然事件S，有 $P(S) = 1$；
- 可列可加性：设 $A_1, A_2, \cdots$是两两互不相容的事件，即对于 $A_i A_j = \varnothing , i \neq j, i, j = 1, 2, \cdots$，有 $P(A_1 \cup A_2 \cup \cdots) = P(A_1) + P(A_2) + \cdots$。

将概率 $P(A)$用来表征事件A在一次试验中发生的可能性的大小。

**性质i** $P(\varnothing) = 0$。

**性质ii（有限可加性）** 若 $A_1, A_2, \cdots, A_n$是两两互不相容的事件，则有 $P(A_1 \cup A_2 \cup \cdots \cup A_n) = P(A_1) + P(A_2) + \cdots + P(A_n)$。

上式称为概率的有限可加性。

**性质iii** 设A，B是两个事件，若 $A \subset B$，则有：

- $P(B - A) = P(B) -P(A)$；
- $P(B) \geq P(A)$。

**性质iv** 对于任一事件A， $P(A) \leq 1$。

**性质v（逆事件的概率）** 对于任一事件A，有 $P(\overline{A}) = 1 - P(A)$。

**性质vi（加法公式）** 对于任意两事件A，B有 $P(A \cup B) = P(A) + P(B) - P(AB)$。

设 $A_1, A_2, A_3$为任意三个事件，则有：

$$
\begin{align*}
P(A_1 \cup A_2 \cup A_3) = & P(A_1) + P(A_2) + P(A_3) - P(A_1 A_2) \\ 
& - P(A_1 A_3) - P(A_2 A_3) + P(A_1 A_2 A_3).
\end{align*}
$$

一般，对于任意n个事件 $A_1, A_2, \cdots, A_n$，可以用归纳法证得：

$$
\begin{align*}
P(A_1 \cup A_2 \cup \cdots \cup A_n) & = \sum_{i = 1}^n P(A_i) - \sum_{i \leq i < j \leq n} P(A_i A_j) \\
& + \sum_{1 \leq i < j< k \leq n} P(A_i A_j A_k) + \cdots + (-1)^{n - 1} P(A_1 A_2 \cdots A_n).
\end{align*}
$$

## 4 等可能概型（古典概型）

如果试验具有以下两个特点：

- 试验的样本空间只包含有限个元素；
- 试验中每个基本事件发生的可能性相同。

这种试验称为等可能概型，也称古典概型。

设试验的样本空间为 $S = \{ e_1, e_2, \cdots, e_n \}$。由于在试验中每个基本事件发生的可能性相同，即有： $P(\{ e_1 \}) = P(\{ e_2 \}) = \cdots = P(\{ e_n \})$。又由于基本事件是两两互不相容的，于是：

$$
\begin{align*}
1 & = P(S) = P(\{ e_1 \} \cup \{ e_2 \} \cup \cdots \cup \{ e_n \}) \\
& = P(\{ e_1 \}) + P(\{ e_2 \}) + \cdots + P(\{ e_n \}) \\
& = nP(\{ e_i \}), \\
\\
& P(\{ e_i \}) = \frac{1}{n}, i = 1, 2, \cdots, n.
\end{align*}
$$

若事件A包含k个基本事件，即 $A = \{ e_{1_1} \} \cup \{ e_{i_2} \} \cup \cdots \cup \{ e_{i_k} \}$，这里 $i_1, i_2, \cdots, i_k$是 $1, 2, \cdots, n$中某k个不同的数，则有：

$$
\begin{align*}
P(A) = \sum_{j = 1}^k P(\{ e_{i_j} \}) = \frac{k}{n} = \frac{A包含的基本事件数}{S中基本事件的总数}.
\end{align*}
$$

上式就是等可能概型中事件A的概率的计算公式。

- 放回抽样
- 不放回抽样

## 5 条件概率

### （一）条件概率

在事件A发生的条件下事件B发生的概率，记为 $P(B|A)$。 

**定义** 设A，B是两个事件，且 $P(A) > 0$，称 $P(B|A) = \frac{P(AB)}{P(A)}$。为在事件A发生的条件下事件B发生的条件概率。

条件概率 $P(\cdot | A)$符合概率定义中的三个条件：

- 非负性：对于每一事件B，有 $P(B|A) \geq 0$；
-  规范性：对于必然事件S，有 $P(S|A) = 1$；
- 可列可加性：设 $B_1, B_2, \cdots$是两两互不相容的事件，则有 $P(\bigcup \limits_{i = 1}^{\infty} B_i | A) = \sum \limits_{i = 1}^{\infty} P(B_i | A)$。

### （二）乘法定理

**乘法定理** 设 $P(A) > 0$，则有 $P(AB) = P(B|A) P(A)$。该式称为乘法公式。

设A，B，C为事件，且 $P(AB) > 0$，则有 $P(ABC) = P(C|AB) P(B|A) P(A)$。

一般，设 $A_1, A_2, \cdots, A_n$为n个事件， $n \geq 2$，且 $P(A_1 A_2 \cdots A_{n - 1}) > 0$，则有 $P(A_1 A_2 \cdots A_n) = P(A_n | A_1 A_2 \cdots A_{n - 1}) P(A_{n - 1} | A_1 A_2 \cdots A_{n - 2}) \cdots P(A_2 | A_1) P(A_1)$。

### （三）全概率公式和贝叶斯公式

**定义** 设S为试验E的样本空间， $B_1, B_2, \cdots, B_n$为E的一组事件。若：

- $B_i B_j = \varnothing, i \neq j, i, j = 1, 2, \cdots, n$；
- $B_1 \cup B_2 \cup \cdots \cup B_n = S$，

则称 $B_1, B_2, \cdots, B_n$为样本空间S的一个划分。

若 $B_1, B_2, \cdots, B_n$是样本空间的一个划分，那么，对每次试验，事件 $B_1, B_2, \cdots, B_n$中必有一个且仅有一个发生。

**定理** 设试验E的样本空间为S，A为E的事件， $B_1, B_2, \cdots, B_n$为S的一个划分，且 $P(B_i) > 0 (i = 1, 2, \cdots, n)$，则 $P(A) = P(A|B_1) P(B_1) + P(A|B_2) P(B_2) \cdots + P(A|B_n) P(B_n)$。该式称为全概率公式。

**定理** 设试验E的样本空间为S。A为E的事件， $B_1, B_2, \cdots, B_n$为S的一个划分，且 $P(A) > 0, P(B_i) > 0 (i = 1, 2, \cdots, n)$，则 $P(B_i | A) = \frac{P(A|B_i) P(B_i)}{\sum \limits_{j=1}^n P(A|B_j) P(B_j)}, i = 1, 2, \cdots, n$。上式称为贝叶斯（Baves）公式。

上面两个公式中取n=2，并将 $B_1$记为B，此时 $B_2$就是 $\overline{B}$，那么全概率公式和贝叶斯公式分别成为：

- $P(A) = P(A | B) P(B) + P(A | \overline{B}) P(\overline{B})$，
- $P(B|A) = \frac{P(AB)}{P(A)} = \frac{P(A | B) P(B)}{P(A | B) P(B) + P(A | \overline{B}) P(\overline{B})}$。

由以往的数据分析得到的概率，叫做先验概率。而在得到信息之后再重新加以修正的概率，叫做后验概率。

## 6 独立性

设A，B是试验E的两事件，若 $P(A)  > 0$，可以定义 $P(B | A)$。一般，A的发生对B发生的概率是有影响的，这时 $P(B | A) \neq P(B)$，只有在这种影响不存在时才会有 $P(B | A) = P(B)$，这时有 $P(AB) = P(B | A) P(A) = P(A) P(B)$。

**定义** 设A，B是两事件，如果满足等式 $P(AB) = P(A) P(B)$，则称事件A，B相互独立，简称A，B独立。

容易知道，若 $P(A) > 0, P(B) > 0$，则A，B相互独立与A，B互不相容不能同时成立。

**定理1** 设A，B是两事件，且 $P(A) > 0$。若A，B相互独立，则 $P(B | A) = P(B)$，反之亦然。

**定理2** 若事件A与B相互独立，则下列各事件也相互独立： A与 $\overline{B}$， $\overline{A}$与B， $\overline{A}$与 $\overline{B}$。

**定义** 设A，B，C是三个事件，如果满足等式：

$$
\begin{align*}
& P(AB) = P(A) P(B), \\
& P(BC) = P(B) P(C), \\
& P(AC) = P(A) P(C), \\
& P(ABC) = P(A) P(B) P(C),
\end{align*}
$$

则称事件A，B，C相互独立。

一般地，设 $A_1, A_2, \cdots, A_n$是 $n(n \geq 2)$个事件，如果对于其中任意2个，任意3个， $\cdots$，任意n个事件的积事件的概率，都等于各事件概率之积，则称事件 $A_1, A_2, \cdots, A_n$相互独立。

由定义，可得到以下推论：

- 若事件 $A_1, A_2, \cdots, A_n (n \geq 2)$相互独立，则其中任意 $k (2 \leq k \leq n)$个事件也是相互独立的。
- 若n个事件 $A_1, A_2, \cdots, A_n (n \geq 2)$相互独立，则将 $A_1, A_2, \cdots, A_n$中任意多个事件换成它们各自的对立事件，所得的n个事件仍相互独立。

两事件相互独立的含义是它们中一个已发生，不影响另一个发生的概率。

# 第二章 随机变量及其分布

## 1 随机变量

**定义** 设随机试验的样本空间 $S = \{e\}$。 $X = X(e)$是定义在样本空间S上的实值单值函数。称 $X = X(e)$为随机变量。

一般以大写的字母如 $X, Y, Z, W, \cdots$表示随机变量，而以小写字母 $x, y, z, w, \cdots$表示实数。

一般，若L是一个实数集合，将X在L上取值写成 $\{X \in L\}$。它表示事件 $B = \{e | X(e) \in L\}$，即B是由S中使得 $X(e) \in L$的所有样本点e所组成的事件，此时有 $P\{X \in L\} = P(B) = P \{e | X(e) \in L\}$。

## 2 离散型随机变量及其分布律

有些随机变量，它全部可能取到的值是有限个或可列无限多个，这种随机变量称为离散型随机变量。

设离散型随机变量X所有可能取的值为 $x_k (k = 1, 2, \cdots)$，X取各个可能值的概率，即事件 $\{X = x_k\}$的概率，为： $P \{X = x_k\} = p_k, k = 1, 2, \cdots$。由概率的定义， $p_k$满足如下两个条件：

- $p_k \geq 0, k = 1, 2, \cdots$；
- $\sum \limits_{k = 1}^{\infty} p_k = 1$。

称 $P \{X = x_k\} = p_k, k = 1, 2, \cdots$式为离散型随机变量X的分布律。分布律也可以用表格的形式来表示。

### （一）(0-1)分布

设随机变量X只可能取0与1两个值，它的分布律是 $P \{X = k\} = p^k(1-p)^{1- k}, k = 0, 1 \quad (0 < p < 1)$，则称X服从以p为参数的(0-1)分布或两点分布。

对于一个随机试验，如果它的样本空间只包含两个元素，即 $S = \{e_1, e_2\}$，我们总能在S上定义一个服从(0-1)分布的随机变量：

$$
X = X(e) = 

\begin{cases}
0, 当 e = e_1, \\
1, 当 e = e_2
\end{cases}
$$
来描述这个随机试验的结果。

### （二）伯努利试验、二项分布

设试验E只有两个可能结果： $A$及 $\overline{A}$，则称E为伯努利（Bernoulli）试验，设 $P(A) = p (0 < p < 1)$，此时 $P(\overline{A}) = 1- p$。将E独立重复地进行n次，则称这一串重复的独立试验为n重伯努利试验。


以X表示n重伯努利试验中事件A发生的次数，X是一个随机变量。X所有可能取的值为 $0, 1, 2, \cdots, n$。由于各次试验是相互独立的，因此事件A在指定的 $k (0 \leq k \leq n)$次试验中发生，在其他n-k次试验中A不发生的概率为：

$$
\underbrace{p \cdot p \cdot \cdots \cdot p}_{k个} \cdot \underbrace{(1 - p) \cdot (1 - p) \cdot \cdots \cdot (1 - p)}_{n - k 个} = p^k (1 - p)^{n - k}
$$

这种指定的方式共有 $\binom{n}{k}$种，它们是两两互不相容的，故在n次试验中A发生k次的概率为 $\binom{n}{k} p^k (1 - p)^{n - k}$，记 $q = 1 - p$，即有： $P\{X = k\} = \binom{n}{k}p^k q^{n - k}, k = 0, 1, 2, \cdots , n$。显然：

$$
\begin{align*}
P \{X = k\} \geq 0, k = 0, 1, 2, \cdots, n; \\
\sum_{k = 0}^n P \{X = k\} = \sum_{k = 0}^n \binom{n}{k} p^k q^{n - k} = (p + q)^n = 1. 
\end{align*}
$$

即 $P \{X = k\}$满足 $p_k \geq 0, k = 1, 2, \cdots$和 $\sum \limits_{k = 1}^{\infty} p_k = 1$两个条件。 $\binom{n}{k} p^k q^{n - k}$刚好是二项式 $(p + q)^n$的展开式中出现 $p^k$的那一项，称随机变量X服从参数n，p的二项分布，并记为 $X \sim b(n, p)$。

特别的，当n=1时，二项分布化为 $P \{X = k\} = p^k q^{1 - k}, k = 0, 1$，这就是(0-1)分布。

### （三）泊松分布

设随机变量X所有可能取值为 $0, 1, 2, \cdots$，而取各个值的概率为 $P \{X = k\} = \frac{\lambda^k e^{- \lambda}}{k!}, k = 0, 1, 2, \cdots$，其中 $\lambda > 0$是常数。则称X服从参数为 $\lambda$的泊松分布，记为 $X \sim \pi (\lambda)$。

**泊松定理** 设 $\lambda > 0$是一个常数，n是任意正整数，设 $np_n = \lambda$，则对于任一固定的非负整数k，有 $\lim \limits_{n \to \infty} \binom{n}{k} p_n^k (1 - p_n)^{n - k} = \frac{\lambda^k e^{- \lambda}}{k!}$。

定理的条件 $np_n = \lambda$（常数）意味着当n很大时 $p_n$必定很小，因此，上述定理表明当n很大，p很小（ $np = \lambda$）时有以下近似式 $\binom{n}{k} p^k (1 - p)^{n - k} \approx \frac{\lambda^k e^{- \lambda}}{k!}$（其中 $\lambda = np$），也就是说以n，p为参数的二项分布的概率值可以由参数为 $\lambda = np$的泊松分布的概率值近似。

一般，当 $n \geq 20, p \leq 0.05$时用 $\frac{\lambda^k e^{- \lambda}}{k!} (\lambda = np)$作为 $\binom{n}{k} p^k (1 - p)^{n - k}$的近似值效果颇佳。

## 3 随机变量的分布函数

**定义** 设X是一个随机变量，x是任意实数，函数 $F(x) = P \{X \leq x\}, -\infty < x < \infty$称为X的分布函数。

对于任意实数 $x_1, x_2 (x_1 < x_2)$，有 $P \{x_1 < X \leq x_2\} = P \{X \leq x_2\} - P \{X \leq x_1\} = F(x_2) - F(x_1)$，因此，若已知X的分布函数，就知道X落在任一区间 $(x_1, x_2]$上的概率。

如果将X看成是数轴上的随机点的坐标，那么，分布函数 $F(x)$在x处的函数值就表示X落在区间 $(-\infty, x]$上的概率。


分布函数 $F(x)$具有以下基本性质：

- $F(x)$是一个不减函数。由 $P \{x_1 < X \leq x_2\} = P \{X \leq x_2\} - P \{X \leq x_1\} = F(x_2) - F(x_1)$式对于任意实数 $x_1, x_2 (x_1 < x_2)$，有 $F(x_2) - F(x_1) = P \{x_1 < X \leq x_2\} \geq 0$。
- $0 \leq F(x) \leq 1$，且：
	- $F(-\infty) = \lim \limits_{x \to -\infty} F(x) = 0$，
	- $F(\infty)= \lim \limits_{x \to \infty} F(x) = 1$。
- $F(x + 0) = F(x)$，即 $F(x)$是右连续的。

一般，设离散型随机变量X的分布律为 $P \{X = x_k\} = p_k, k = 1, 2, \cdots$，由概率的可列可加性得X的分布函数为 $F(x) = P \{X \leq x\} = \sum \limits_{x_k \leq x} P \{X = x_k\}$，即： $F(x) = \sum \limits_{x_k \leq x} p_k$，这里和式是对于所有满足 $x_k \leq x$的k求和的。分布函数 $F(x)$在 $x = x_k (k = 1, 2, \cdots)$处有跳跃，其跳跃值为 $p_k = P \{X = x_k\}$。

## 4 连续型随机变量及其概率密度

如果对于随机变量X的分布函数 $F(x)$，存在非负函数 $f(x)$，使对于任意实数x有 $F(x) = \int_{- \infty}^x f(t) \mathrm{d}t$，则称X为连续型随机变量，其中函数 $f(x)$称为X的概率密度函数，简称概率密度。

概率密度 $f(x)$具有以下性质：

1. $f(x)\geq 0$；
2. $\int_{- \infty}^{\infty} f(x) \mathrm{d}x = 1$；
3. 对于任意实数 $x_1, x_2, (x_1 \leq x_2)$， $P \{x_1 < X \leq x_2\} = F(x_2) - F(x_1) = \int_{x_1}^{x_2} f(x) \mathrm{d}x$；
4. 若 $f(x)$在点x处连续，则有 $F^{\prime}(x) = f(x)$。

- 由性质2知道介于曲线 $y = f(x)$与 $Ox$轴之间的面积等于1。
- 由性质3知道X落在区间 $(x_1, x_2]$的概率 $P \{x_1 < X \leq x_2\}$等于区间 $(x_1, x_2]$上曲线 $y = f(x)$之下的曲边梯形的面积。
- 由性质4可知在 $f(x)$的连续点x处有 $f(x) = \lim \limits_{\Delta x \to 0^+} \frac{F(x + \Delta x) - F(x)}{\Delta x} = \lim \limits_{\Delta x \to 0^+} \frac{P \{x < X \leq x + \Delta x\}}{\Delta x}$。

由上式可知，若不计高阶无穷小，有 $P \{x < X \leq x + \Delta x\} \approx f(x) \Delta x$，这表示X落在区间 $(x, x + \Delta x]$上的概率近似地等于 $f(x) \Delta x$。

对于连续性随机变量X来说，它取任一指定实数值a的概率均为0，即 $P \{X = a\} = 0$。据此，在计算连续型随机变量落在某一区间的概率时，可以不必区分该区间是开区间或闭区间或半闭区间。例如有： $P \{a < X \leq b\} = P \{a \leq X \leq b\} = P \{a < X < b\}$。在这里，事件 $\{X = a\}$并非不可能事件，但有 $P \{X = a\} = 0$。这就是说，若A是不可能事件，则有 $P(A) = 0$；反之，若 $P(A) = 0$，并不一定意味着A是不可能事件。

以后提到一个随机变量X的概率分布时，指的是它的分布函数；或者，当X是连续型随机变量时，指的是它的概率密度，当X是离散型随机变量时，指的是它的分布律。

### （一）均匀分布

若连续型随机变量X具有概率密度：

$$
f(x) = 
\begin{cases}
\frac{1}{b - a}, & a < x < b, \\
0, & 其他,
\end{cases}
$$

则称X在区间 $(a, b)$上服从均匀分布，记为 $X \sim U(a, b)$。

易知 $f(x) \geq 0$且 $\int_{- \infty}^{\infty} f(x) \mathrm{d}x = 1$。

在区间 $(a, b)$上服从均匀分布的随机变量X，具有下述意义的等可能性，即它落在区间 $(a, b)$中任意等长度的子区间内的可能性是相同的。或者说它落在 $(a, b)$的子区间内的概率只依赖于子区间的长度而与子区间的位置无关。

X的分布函数为：

$$
F(x) = 
\begin{cases}
0, & x < a, \\
\frac{x - a}{b - a}, & a \leq x < b, \\
1, & a \geq b.
\end{cases}
$$
### （二）指数分布

若连续型随机变量X的概率密度为：

$$
f(x) = 
\begin{cases}
\frac{1}{\theta} e^{-\frac{x}{\theta}}, & x > 0, \\
0, & 其他.
\end{cases}
$$

其中 $\theta > 0$为常数，则称X服从参数为 $\theta$的指数分布。

易知 $f(x) \geq 0$，且 $\int_{- \infty}^{\infty} f(x) \mathrm{d}x = 1$。

随机变量X的分布函数为：

$$
F(x) = 

\begin{cases}
1 - e^{-\frac{x}{\theta}}, & x > 0, \\
0, & 其他.
\end{cases}
$$

服从指数分布的随机变量X具有以下性质：对于任意 $s, t > 0$，有 $P \{X > s + t | X > s\} = P \{X > t\}$。该性质称为无记忆性。

指数分布在可靠性理论与排队论中有广泛的应用。

### （三）正态分布

若连续型随机变量X的概率密度为 $f(x) = \frac{1}{\sqrt{2 \pi} \sigma} e^{- \frac{(x - \mu)^2}{2 \sigma^2}}, -\infty < x < \infty$，其中 $\mu, \sigma (\sigma > 0)$为常数，则称X服从参数为 $\mu, \sigma$的正态分布或高斯（Gauss）分布，记为 $X \sim N(\mu, \sigma^2)$。

具有以下性质：

1. 曲线关于 $x = \mu$对称。这表明对于任意 $h > 0$有 $P \{\mu - h < X \leq \mu \} = P \{\mu < X \leq \mu + h\}$。
2. 当 $x = \mu$时取到最大值 $f(\mu) = \frac{1}{\sqrt{2 \pi}\sigma}$。

x离 $\mu$越远， $f(x)$越小。这表明对于同样长度的区间，当区间离 $\mu$越远，X落在这个区间上的概率越小。

在 $x = \mu \pm \sigma$处曲线有拐点。曲线以 $Ox$轴为渐近线。

如果固定 $\sigma$，改变 $\mu$的值，则图形沿着 $Ox$轴平移，而不改变其形状，可见正态分布的概率密度曲线 $y = f(x)$的位置完全由参数 $\mu$所确定。 $\mu$称为位置参数。

如果固定 $\mu$，改变 $\sigma$，由于最大值 $f(\mu) = \frac{1}{\sqrt{2 \pi}\sigma}$，可知当 $\sigma$越小时图形变得越尖，因而X落在 $\mu$附近的概率越大。

X的分布函数为 $F(x) = \frac{1}{\sqrt{2 \pi}\sigma} \int_{- \infty}^x e^{-\frac{(t - \mu)^2}{2 \sigma^2}}\mathrm{d}t$，特别的，当 $\mu = 0, \sigma = 1$时称随机变量X服从标准正态分布。其概率密度和分布函数分别用 $\varphi(x), \Phi(x)$表示，即有：

- $\varphi(x) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^2}{2}}$，
- $\Phi(x) = \frac{1}{2 \pi} \int_{- \infty}^x e^{-\frac{t^2}{2}}\mathrm{d}t$。

易知 $\Phi(-x) = 1- \Phi(x)$。

一般，若 $X \sim N(\mu, \sigma^2)$，只要通过一个线性变换就能将它化成标准正态分布。

**引理** 若 $X \sim N(\mu, \sigma^2)$，则 $Z = \frac{X - \mu}{\sigma} \sim N(0, 1)$。

若 $X \sim N(\mu, \sigma^2)$，则它的分布函数 $F(x)$可写成 $F(x) = P \{X \leq x\} = P \{\frac{X - \mu}{\sigma} \leq \frac{x - \mu}{\sigma}\} = \Phi(\frac{x - \mu}{\sigma})$。对于任意区间 $(x_1, x_2]$，有 $P \{x_1 < X \leq x_2\} = P \{\frac{x_1 - \mu}{\sigma} < \frac{X - \mu}{\sigma} \leq \frac{x_2 - \mu}{\sigma}\} = \Phi(\frac{x_2 - \mu}{\sigma}) - \Phi(\frac{x_1 - \mu}{\sigma})$。

尽管正态变量的取值范围是 $(-\infty, \infty)$，但它的值落在 $(\mu - 3 \sigma, \mu + 3 \sigma)$内几乎是肯定的事，这就是 $3\sigma$法则。

对于标准正态随机变量，引入上 $\alpha$分位点的定义，设 $X \sim N(0, 1)$，若 $z_{\alpha}$满足条件 $P \{X > z_{\alpha}\} = \alpha, 0 < \alpha < 1$，则称点 $z_{\alpha}$为标准正态分布的上 $\alpha$分位点。

常用的 $z_{\alpha}$的值：


| $\alpha$ | $z_{\alpha}$ |
| -------- | ------------ |
| 0.001    | 3.090        |
| 0.005    | 2.576        |
| 0.01     | 2.326        |
| 0.025    | 1.960        |
| 0.05     | 1.645        |
| 0.10     | 1.282        |

由 $\varphi(x)$图形的对称性知道 $z_{1 - \alpha} = - z_{\alpha}$。

## 5 随机变量的函数的分布

**定理** 设随机变量X具有概率密度 $f_X (x), - \infty < x < \infty$，又设函数 $g(x)$出处可导且恒有 $g^{\prime}(x) > 0$（或恒有 $g^{\prime}(x) < 0$），则 $Y = g(X)$是连续型随机变量，其概率密度为：

$$
f_Y(y) = 
\begin{cases}
f_X[h(y)]|h^{\prime}(y)|, & \alpha < y < \beta, \\
0, & 其他
\end{cases}
$$

其中 $\alpha = \min \{g(-\infty), g(\infty)\}, \beta = \max \{g(-\infty), g(\infty)\}$， $h(y)$是 $g(x)$的反函数。

# 第三章 多维随机变量及其分布

## 1 二维随机变量

设E是一个随机试验，它的样本空间是 $S = \{e\}$，设 $X = X(e)$和 $Y = Y(e)$是定义在S上的随机变量，由它们构成的一个向量 $(X, Y)$，叫做二维随机向量或二维随机变量。

**定义** 设 $(X, Y)$是二维随机变量，对于任意实数 $x, y$，二元函数： $F(x, y) = P \{(X \leq x) \cap (Y \leq y)\} \overset{记成}{=} P\{X \leq x, Y \leq y\}$，称为二维随机变量 $(X, Y)$的分布函数，或称为随机变量X和Y的联合分布函数。

如果将二维随机变量 $(X, Y)$看成是平面上随机点的坐标，那么，分布函数 $F(x, y)$在 $(x, y)$处的函数值就是随机点 $(X, Y)$落在以点 $(x, y)$为顶点而位于该点左下方的无穷矩形域内的概率。

随机点 $(X, Y)$落在矩形域 $\{(x, y) | x_1 < x \leq x_2, y_1 < y \leq y_2\}$的概率为 $P \{x_1 < X \leq x_2, y_1 < Y \leq y_2\} = F(x_2, y_2) - F(x_2, y_1) + F(x_1, y_1) - F(x_1, y_2)$。

分布函数 $F(x, y)$具有以下的基本性质：

1. $F(x, y)$是变量x和y的不减函数，即对于任意固定的y，当 $x_2 > x_1$时 $F(x_2, y) \geq F(x_1, y)$；对于任意固定的x，当 $y_2 > y_1$时 $F(x, y_2) \geq F(x, y_1)$。
2. $0 \leq F(x, y) \leq 1$，且：
	- 对于任意固定的y， $F(-\infty, y) = 0$，
	- 对于任意固定的x， $F(x, -\infty) = 0$，
	- $F(-\infty, -\infty) = 0$，
	- $F(\infty, \infty) = 1$。
3. $F(x + 0, y) = F(x, y), F(x, y + 0) = F(x, y)$，即 $F(x, y)$关于x右连续，关于y也右连续。
4. 对于任意 $(x_1, y_1), (x_2, y_2), x_1 < x_2, y_1 < y_2$，下述不等式成立： $F(x_2, y_2) - F(x_2, y_1) + F(x_1, y_1) - F(x_1, y_2) \geq 0$。

如果二维随机变量 $(X, Y)$全部可能取到的值是有限对或可列无限多对，则称 $(X, Y)$是离散型的随机变量。

设二维离散型随机变量 $(X, Y)$所有可能取的值为 $(x_i, y_j), i, j = 1, 2, \cdots$，记 $P \{X = x_i, Y = y_j\} = p_{ij}, i, j = 1, 2, \cdots$，则由概率的定义有 $p_{ij} \geq 0$， $\sum \limits_{i = 1}^{\infty} \sum \limits_{j = 1}^{\infty} p_{ij} = 1$。称 $P \{X = x_i, Y = y_j\} = p_{ij}, i, j = 1, 2, \cdots$为二维离散型随机变量 $(X, Y)$的分布律，或随机变量X和Y的联合分布律。

将 $(X, Y)$看成一个随机点的坐标，离散型随机变量X和Y的联合分布函数为 $F(x, y) = \sum \limits_{x_i \leq x} \sum \limits_{y_j \leq y} p_{ij}$，其中和式是对一切满足 $x_i \leq x, y_j \leq y$的i，j来求和的。

对于二维随机变量 $(X, Y)$的分布函数 $F(x, y)$，如果存在非负的函数 $f(x, y)$使对任意x，y有 $F(x, y) = \int_{-\infty}^{y} \int_{-\infty}^{x} f(u, v) \mathrm{d}u \mathrm{d}v$，则称 $(X, Y)$是连续型的二维随机变量，函数 $f(x, y)$称为二维随机变量 $(X, Y)$的概率密度，或称为随机变量X和Y的联合概率密度。

概率密度 $f(x, y)$具有以下性质：

1. $f(x, y) \geq 0$。
2. $\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x, y) \mathrm{d}x \mathrm{d}y = F(\infty, \infty) = 1$。
3. 设G是 $xOy$平面上的区域，点 $(X, Y)$落在G内的概率为 $P \{(X, Y) \in G\} = \iint \limits_G f(x, y) \mathrm{d}x \mathrm{d}y$。
4. 若 $f(x, y)$在点 $(x, y)$连续，则有 $\frac{\partial^2 F(x, y)}{\partial x \partial y} = f(x, y)$。

设E是一个随机试验，它的样本空间是 $S = \{e\}$，设 $X_1 = X_1(e), X_2 = X_2(e), \cdots, X_n = X_n(e)$是定义在S上的随机变量，由它们构成的一个n维向量 $(X_1, X_2, \cdots, X_n)$叫做n维随机向量或n维随机变量。

对于任意n个实数 $x_1, x_2, \cdots, x_n$，n元函数 $F(x_1, x_2, \cdots, x_n) = P \{X_1 \leq x_1, X_2 \leq x_2, \cdots, X_n \leq x_n\}$称为n维随机变量 $(X_1, X_2, \cdots, X_n)$的分布函数或随机变量 $X_1, X_2, \cdots, X_n$的联合分布函数。

## 2 边缘分布


